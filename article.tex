%% 
%% Copyright 2019 Elsevier Ltd
%% 
%% This file is part of the 'CAS Bundle'.
%% --------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'CAS Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for cas-dc documentclass for 
%% double column output.

%\documentclass[a4paper,fleqn,longmktitle]{cas-dc}
%\documentclass[a4paper,fleqn]{cas-dc}
\documentclass[preprint,12pt]{elsarticle}

%\usepackage[authoryear,longnamesfirst]{natbib}
%\usepackage[authoryear]{natbib}
\usepackage[numbers]{natbib}
\usepackage{amsmath}


\usepackage{hyperref}

\usepackage[ruled,vlined]{algorithm2e}
\usepackage[noend]{algcompatible}

\newcommand{\algorithmicinput}{\textbf{input}}

\newcommand{\INPUT}{\item[\algorithmicinput]}



\usepackage{textcomp}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{siunitx}
%\usepackage{mathpazo}

\usepackage{lipsum}
\usepackage[modulo]{lineno}
\usepackage{fnlineno}
\usepackage{listings}

\input{mymacros.tex}

\begin{document}
\let\WriteBookmarks\relax
\def\floatpagepagefraction{1}
\def\textpagefraction{.001}
%\shorttitle{Classification of Parkinson's disease patients using Bayesian deep learning based on fMRI data}
%\shortauthors{Amin Amini, Mayam Amirmazlaghani}


\title{Classification of Parkinson's disease patients using Bayesian deep learning based on fMRI data}



\author[1]{Amin Amini}
\ead{amin-amini@aut.ac.ir}

%\credit{Conceptualization of this study, Methodology, Software}

\author[1]{Maryam Amirmazlaghani}
%\cormark[1]
\ead{mazlaghani@aut.ac.ir}


\address[1]{Department of Computer Engineering and Information Technology, Amirkabir University of Technology, Tehran, Iran}


%\cortext[cor1]{Corresponding author}

\begin{abstract}
The goal of resting-state functional magnetic resonance imaging (fMRI) is to investigate the brain's functional connections by using the temporal similarity between blood oxygenation level-dependent (BOLD) signals in different regions of the brain “at rest” as an indicator of synchronous neural activity.
However having different images of patients' brains regardless of the sequential time-based information, may contain enough data to investigate their brains and enables us to recognize some diseases.
In this paper, we propose a novel method to automatically extract this non-time sequence-based information using a Bayesian deep learning algorithm based on a convolutional neural network (CNN).
Instead of using some predefined points of interest (POIs) we use the whole data in the training phase so those points of the brain which do not contain related information about the disease will be ignored automatically by the trained model.
Moreover, this method does not make any assumptions about the disease, patients, etc.,
makes it a possible universal disease diagnosis approach to differentiate diseases having an impact on brain functionality.
This method is a supervised algorithm with a small number of calculations using three-dimensional CNN.
Each fMRI scan (which contains {\it t} time slices of the brain) of patients will be divided into {\it t} different 3D images enabling us to make the dataset much bigger in number and calculations way simpler.
Subsequently, all of these images are fed to a Bayesian network similar to LeNet-5 (but in three dimensions) to train our model.
Then to determine if a person is suffering from Parkinson's or not, we test his/her {\it t} fMRI images and get {\it t} different results which leads to a fraction (probability) of how unhealthy his/her brain is and if that fraction is above 0.5 we can classify that sample as a Parkinson's patient. As a result, the proposed method would be able to distinguish Parkinson's disease patients from healthy controls accurately. Experimental results confirm the efficiency of the proposed method and its outperformance.
\end{abstract}


%\begin{highlights}
%\item High accuracy with 
%\item Research highlights item 2
%\item Research highlights item 3
%\end{highlights}

\begin{keyword}
Functional magnetic resonance imaging (fMRI) \sep
Resting-state \sep
Disease diagnosis \sep
Bayesian deep learning \sep
Convolutional neural network (CNN) \sep
Parkinson's disease
\end{keyword}


\maketitle

\linenumbers

\section{Introduction}

Parkinson's disease is a long-term degenerative disorder of the central nervous system that mainly affects the motor system. As the disease worsens, non-motor symptoms become more common. The symptoms usually emerge slowly. Early in the disease, the most obvious symptoms are shaking, rigidity, slowness of movement, and difficulty with walking. Thinking and behavioral problems may also occur. Recently, resting-state fMRI has become an extremely popular area of research for neuroimagers as evidenced by the exponential growth in related publications per year \cite{Murphy2013}. The goal of resting-state fMRI is to use the common variance of the fMRI blood oxygenation level dependent (BOLD) signals in different regions of the brain as an indicator of synchronous neural activity. The assumption is that the temporal similarity between the BOLD signals in each region demonstrates that they are in constant communication with one another and thus form a functional network \cite{Calhoun2016}.

There are many ways to define network nodes from fMRI; nodes are often defined as spatial regions of interest, for example, as obtained from fMRI activation or from brain atlases. Alternatively, parcellation via a data-driven clustering of the FMRI data itself (e.g., hierarchical clustering or independent component analysis) can be run to define clusters or components (spatial maps with associated time-slices), which can be considered network nodes \cite{Smith2012}. Furthermore, we are curious to find out if fMRI scans carry enough information without taking their temporal connectivities into account. In other words, does spatial information carry enough data to diagnose Parkinson's disease patients?

The majority of fMRI disease diagnosis algorithms are based on temporal information and functional connectivities in some regions of interest (ROIs)\cite{Adali2014}. For instance, Shen et. al had proposed a method based on functional connectivities in some ROIs, which enabled the differentiation of schizophrenic patients from healthy control with an accuracy of $81.3\%$ \cite{Shen2014}. Another powerful model is the hybrid method of static and dynamic resting-state fMRI connectivities proposed by Rashid et. al. The mentioned method uses structural and functional connectivities coherently to classify schizophrenia and bipolar patients accurately ($=89\%$) \cite{Rashid2016}. In contrast to that, there are some powerful methods such as Sarraf and Tofighi's deep 2D convolutional neural network algorithm which can diagnose Alzheimer's disease patients using their proposed adopted LeNet-5 network as accurate as $96.86\%$ \cite{Sarraf2016}. Moreover, Sarraf and Tofighi's method does not make assumptions about the disease, makes it a possible solution for Parkinson's disease diagnosis.

Sarraf and Tofighi's 2D CNN method is one of the best candidates for Parkinson's disease classification. However, it has some downsides which make it unable to do so. First of all, it needs a huge amount of training samples to learn as expected. Secondly, we have to omit some participants to prevent overfitting \cite{Sarraf2016}. Also, this method consumes a lot of hardware resources and the training phase takes hours to complete.

In this study, we are trying to build a method based on Bayesian deep learning and spatial resting-state fMRI data to diagnose Parkinson's disease accurately. Our proposed method takes advantage of hidden temporal connectivities using Three-dimensional Convolutional Neural Networks (3D CNN) while keeping calculations affordable; thanks to the Bayesian nature of the proposed network. Division of scans to {\it t} different images, on the other hand, speeds up the training phase and keeps our model as simple as possible; and as a result, our algorithm can avoid overfitting. This technique prevents the network from searching for low-level connections among time-series as well as multiplication of the data. Correspondingly, the proposed method can evaluate each validation case {\it t} times to prevent overfitting effectively. Besides, we are trying to avoid any kind of assumptions and conditions about the disease (Parkinson's) and participants. Subsequently, the proposed method might be able to be used in case of other diseases as well. Also, if we can classify patients successfully, we can state that spatial fMRI data carries a lot of hidden information worth investigating in the future.

The rest of this paper is organized as follows. Participant and dataset information, pre-processing steps, tools and materials used, and the proposed method are described respectively in Section \ref{section:materials}. Experiments and results can be seen in Section \ref{section:results}. Conclusion and discussion can be found in Section \ref{section:discussion}. Finally, Section \ref{section:future} contains the limitations and future directions.



\section{Materials and methods}

In this section, first, we introduce the used dataset and data acquisition and then, we take a look at required pre-processing steps to unify the scans. Subsequently, basic tools and models, such as three-dimensional convolutional neural networks (3D CNN) and Bayesian deep learning, will be discussed. Finally, we will comprehensively describe the proposed method.

\label{section:materials}





\subsection{Participants}
\label{section:participants}
We had 30 subjects with ACER over 85 and MMSE over 27, comprising 15 healthy controls \texttt{[HC, age 63.33 ± 5.25, 8 females ]}
and 15 patients diagnosed with Parkinson's disease  \texttt{[PD, age 70.73 ± 4.80, 8 females ]}.
Significant differences in age and ACER aong two groups were found \texttt{(age: p=0.0012 , ACER: p=0.015)}. However no significant difference in MMSE were found \texttt{(MMSE: p=0.315)}.

\subsection{Data acquisition}
\label{section:data}
fMRI scans were obtained from the OpenfMRI project which was acquired on a 3T Siemens Verio with repetition time (TR) = 2.5 s, echo time (TE) = 30ms, flip angle = 80°. Each sample contains 198 slices of $39 \times 64 \times 64$ voxels from the brains of patients. Subjects were instructed to close their eyes and to rest quietly during the scan session \cite{OpenFmri}.

\subsection{Data pre-processing}
\label{section:preprocessing}
The fMRI data were pre-processed using the standard modules of FMRIB Software Library v5.0 \cite{FMRIB}. The pre-processing steps for the anatomical data involved motion correction (MCFLRIT), skull stripping, and spatial smoothing (Gaussian kernel of 5-mm FWHM). Low level noise was removed using a high-pass temporal filtering. The functional images were then aligned to the individual's high-resolution T1-weighted scans, which were subsequently registered to the Montreal Neurological Institute standard space (MNI152) using affine linear registration. and resampled at 2mm cubic voxels. The product of the preprocessing step was used in the experiments.



\subsection{Three-dimensional convolutional neural networks}
\label{section:3dCnn}
3D Convolutional Neural Networks which are inspired by human visual system are similar to classic neural networks. This architecture has been particularly designed based on the explicit assumption that raw data are three-dimensional that enables us to encode certain properties and also to reduce the amount of hyper parameters. The 3D CNN topology utilizes spatial relationships to reduce the number of parameters which must be learned and thus improves upon general feed-forward back propagation training. Figure \ref{fig:CnnSample} demonstrate the 3D CNN architecture and equation \eqref{eq:CnnVal} shows how value of each voxel is calculated from previous layer based on a fixed kernel \texttt{(size = P$\times$Q$\times$R)} and a bias ($b_{ij}$); where $v^{ xyz }_{ ij }$ is the value of an unit at position ($x,y,z$) in the  \texttt{j}th feature map in the \texttt{i}th layers where $f$ is the activation function, $m$ indexes over the set of
feature maps in the $(i-1)$th layer connected to the current feature map $w^{pqr}_{ijm}$ is the value at the position $(p,q,r)$ of the kernel connected to the $m$th feature map, and $P_i$, $Q_i$ and $R_i$ are the height, width and depth of the kernel, respectively \cite{Ji2013}.

\begin{equation}
v^{ xyz }_{ ij } = \\
f(  \\
b_{ij} +  \\
\sum_m \\ 
\sum_{p=0}^{P_i-1} \\
\sum_{q=0}^{Q_i-1} \\
\sum_{r=0}^{R_i-1} \\
\; w^{pqr}_{ijm}  \\
\; v ^ { (x+p)(y+q)(z+r) }_{ (i-1)m } \\
) \label{eq:CnnVal}
\end{equation}

Since fMRI images are 3D time series and our experiments try to find out if images contain any useful information despite their sequences, three dimensional CNN can be used as our computational core. A simple 3D CNN can be seen in Figure \ref{fig:CnnSample}.

\begin{figure*}
	\begin{center}
	\includegraphics[width=0.8\linewidth]{images/3dCnn}
	\end{center}
	\caption{3D CNN demonstration (kernel size = 3$\times$3$\times$3).}
	\label{fig:CnnSample}
\end{figure*}




\subsection{Bayesian deep learning}
\label{section:bayesianDL}
Deep learning has achieved significant success in many perception tasks including seeing (visual object recognition), reading (text understanding), and hearing (speech recognition). These are undoubtedly fundamental tasks for a functioning comprehensive artificial intelligence (AI) or data engineering (DE) system. However, in order to build a real AI/DE system, simply being able to see, read, and hear is far from enough. It should master
the ability of thinking.

Take medical diagnosis as an example. Besides seeing
visible symptoms (or medical images from MRI) and hearing descriptions from patients, a doctor has to look for relations among all the symptoms and preferably infer the corresponding etiology. Only after that can the doctor provide medical advice for the patients. In this example, although the abilities of seeing and hearing allow the doctor to acquire information from the patients, it is the thinking part that defines a doctor. Specifically, the ability of thinking here could involve causal inference, logic deduction, and dealing with uncertainty, which is apparently beyond the capability of conventional deep learning methods \cite{Wang2016}.

A neural network with arbitrary depth and non-linearities, with dropout applied before every weight layer, is mathematically equivalent to an approximation to the probabilistic deep Gaussian process (GP) \cite{Gal2016}.

Let $\hat{y}$ be the output of a NN model with $L$ layers and a loss function {\it E(·, ·)} such as the softmax loss or the Euclidean loss (square loss).We denote by $W_i$ the NN’s weight matrices of dimensions $K_i \times K_{i-1}$, and by $b_i$ the bias vectors of dimensions $K_i$ for each layer $i = 1, ..., L$. We denote by $y_i$ the observed output corresponding to input $x_i$ for $1 \leq i \leq N$ data points, and the input and output sets as $X, Y$. During NN optimization a regularization term is often added. We often use $L2$ regularization weighted by some weight decay $\lambda$, resulting in a minimization objective (often referred to as cost) and it can written as Equation  \eqref{eq:bayesianCnnDroupout} \cite{Gal2016}.

\begin{equation}
\mathcal{L}_{dropout} := 
    {1 \over N} \sum_{i=1}^{N} E(y_i , \hat{y_i}) + \\
    \lambda \sum_{i=1}^{L} ( \left|\left| W_i \right|\right|_2^2 + \left|\left| b_i \right|\right|_2^2 )
\label{eq:bayesianCnnDroupout} 
\end{equation}

Now of if we add dropout to the calculations each unit may remain the same with probability $p_i$ or dropped out (its value is set to zero). We use the same values in the backward pass propagating the derivatives to the parameters. Assume we are given a covariance function of the form of Equation \eqref{eq:nnCovariance}.

\begin{equation}
K(x, y) = \int p(w)p(b) \sigma (w^T x + b) \sigma (w^T y + b) dw db
\label{eq:nnCovariance}
\end{equation}

with some element-wise non-linearity {\it $\sigma$(·)} and distributions $p(w), p(b)$. It had been shown that a deep Gaussian process with L layers and covariance function $K(x,y)$ can be approximated by placing a variational distribution over each component of a spectral decomposition of the GPs’ covariance functions.

Let $W_i$ be a random matrix of dimensions $K_i \times K_{i-1}$ for each layer $i$, and write
$\omega = \{ W_i \}^L_{i=1}$. A priori,we let each row of $W_i$ distribute according to the $p(W)$ above. In addition, assume vectors $m_i$ of dimensions $K_i$ for each GP layer. The predictive probability of the deep GP model given some precision parameter $\tau > 0$ can be parameterized as Equation \eqref{eq:gpPriority}.

\begin{eqnarray}
\label{eq:gpPriority}
p(y | x,X,Y) = \int p(y|x,\omega) p(\omega|X,Y)d\omega \\ 
p(y|x,\omega) = \mathcal{N} (y ; \hat{y} (x,\omega) , \tau^{-1} I_D )  \nonumber \\
\hat{y} (x, \omega = \{ W_1, ..., W_L \}) =  \nonumber \\
\sqrt{1 \over K_L} W_L \sigma( ...  \sqrt{1 \over K_1} W_2 \sigma( W_1 x + m_1 ) ... )  \nonumber
\end{eqnarray}

The posterior distribution $p(\omega|X,Y)$ in Equation \eqref{eq:gpPriority} is intractable. It had been shown that if we use a distribution over matrices whose columns are randomly set to zero, we can recover Equation \eqref{eq:bayesianCnnDroupout} \cite{Gal2016}. Note that previously mentioned distribution $q(\omega)$ can be defined as:

\begin{eqnarray}
W_i &=& M_i \cdot diag([ z_{i,j} ]^{K_i}_{j=1} ) \nonumber \\ 
z_{i,j} &=& Bernoulli(p_i) \; \forall \; 1 \le i \le L \; , \; 1 \le j \le K_{i-1} \nonumber
\end{eqnarray}
\newline
given some probabilities $p_i$ and matrices $M_i$ as variational parameters. The variable $z_{i,j} = 0$ corresponds then to unit $j$ in layer $i-1$ being dropped out as an input to layer $i$. Subsequently if we use a dropout in 3D convolutional neural network, it would be a practice of Bayesian 3D CNN.





\subsection{Proposed method}
\label{section:proposedMethod}
As mentioned before, our experiment aims to find out if fMRI scans carry any hidden information without taking time-based sequences in action. Accordingly, we examined some previous researches in this field and an eye-catching example of this glance is Sarraf and Tofighi's adopted LeNet-5 architecture \cite{Sarraf2016}. Their algorithm concatenates fMRI images based on depth ($z$) and time ($t$) axis and does not make any assumptions about the disease or the data (except their unknown patient selection criteria), making it a potential applicable solution to different disease diagnosis tasks. In brief, each patient's scan is presented as a huge two-dimensional matrix which is then fed to a CNN network. Although this method has shown huge success in the case of Alzheimer's (based on large ADNI dataset), our experiments clarify that it is not suitable for Parkinson's disease diagnosis with a small dataset (such as OpenfMRI ds000245). In addition to that, Sarraf and Tofighi's method consumes a huge amount of memory and demands a powerful processor due to its large dimensions of data.

Without a doubt, fMRI scans are nothing but spatial and temporal connectivities. As we aim to focus on spatial relations and put temporal ones aside, our algorithm must try to keep all of that information in calculations. Besides, Sarraf and Tofighi's method loses a lot of these connectivities by flattening data toward the $z$ axis. In addition to that, the mentioned data conversion will increase the model complexity and variance, especially in a case like Parkinson's disease dataset. In fact, by resizing 198 slices of $39 \times 64 \times 64$ voxels to a 2D $2496 \times 12672$ pixels, we are adding a lot of unnecessarily and incorrect spatial connectivities based on the $t$ axis and losing some important ones in the $z$ axis by misplacing them. As a result, it is predictable that flattening algorithm may lead to overfitting and compute-intensive calculations which can be seen in Figure \ref{fig:SarrafParkinsonTestResult}. This experiment ran for 5 epochs (same as the article itself) on an NVIDIA\textsuperscript{\tiny\textregistered} GTX1080 and took $33h \; 55m \; 36s$ {\tiny{($=6h \; 47m \; 7s$ for each epoch)}}. From this experiment, we can easily observe the overfitting as the validation accuracy goes up and down alternatively, and the network is not able to improve the accuracy. Additionally, if we take a look at the loss diagram, we will find out that after the first epoch (which is highlighted by dots in the diagrams), no sensible change is happening to both parameters. Also, it worth mentioning that the model is trying to escape the regional optimum by increasing the loss of the training data while it faces no success.


\begin{figure*}
	\includegraphics[width=\linewidth]{images/SarrafParkinsonTestResult}
	\caption{Parkinson's disease diagnosis accuracy and loss using Sarraf and Tofighi's algorithm.}
	\label{fig:SarrafParkinsonTestResult}
\end{figure*}


In order to conquer the mentioned downsides of a conventional CNN in Parkinson's disease diagnosis, we will introduce our method which keeps spatial information and can overcome overfitting by reducing model variance. To do so, the proposed algorithm will keep the $z$ index of data and feed them into a 3D Bayesian CNN. As discussed in Section \ref{section:bayesianDL} if we add dropouts before each convolution layer, our model will turn into a deep Bayesian convolutional neural network that can avoid overfitting. Dropouts remove some units (by setting their output values to zero) temporarily which enables other units to justify their weights. Consequently, remaining units in the training phase can precisely adjust their weights to more appropriate ranges if they already hold acceptable values, or keep away from unwanted boundaries noticeably if needed. In addition to that, Bayesian networks are dramatically less compute-intensive and can solve problems in even a single epoch. Hence, a mid-end CPU can be used instead of a high-end GPU in experiments.

As we meant to put temporal data aside, we can assume that the fMRI data for each participant is $t$ different 3D images we had obtained from their brain (regardless of time-based sequences). Correspondingly this assumption will multiply our dataset samples by $t (=198)$, enabling us to train our model faster and escape overfitting. On the other hand, in the test phase, our model won't just give binary predictions about a participant being a Parkinson's patient or a healthy control, but it can give us an approximation about the probability of a person being healthy or not. In this step, the trained network will give $t$ different predictions for each person (based on $t$ images) providing a ratio, which corresponds to a probability of healthiness, and we can set a criterion (like $0.5$) to decide if someone belongs to HC class or not.


First of all, input data will be preprocessed using Algorithm \ref{alg:preprocessing}, which removes noises and non-informational data parts (such as the skull). In addition to that, each patient's scan will be normalized to a standard space that boosts the learning phase's efficiency. This step is followed by dividing each sample (containing $t$ 3D fMRI time-slices) to $t$ different images. For instance, in Parkinson's dataset, 30 samples consisted of 198 time-slices of \texttt{$39 \times 64 \times 64$} voxels will turn into $5940$ 3D images. We convert these data to TFRECORD format to improve performance. Furthermore, for each experiment, six participants ($20\%$ of all data) from both groups are randomly selected, and their $t$ time-slices are set aside for the test phase. On the other hand, the rest of the data (which are $24 \times 198$ labeled time-slices) will be shuffled and fed to our 3D deep Bayesian convolutional neural network. We use the first 159 time-slices ($80\%$) as training samples while the remnants will be our validation portion of data correspondingly. 


\begin{algorithm}
	\caption{Data preparation}
	\label{alg:preprocessing}
	
	\begin{algorithmic}[1]
		
		\INPUT{raw fMRI images}
		\STATE Intra-modal motion correction using \textbf{MCFLIRT}. it loads the time-series in its entirity and will default to the middle volume as an initial template image. A coarse 8mm search for the motion parameters is then carried out using the cost function specified followed by two subsequent searches at 4mm using increasingly tighter tolerances. All optimizations use trilinear interpolation.
		\STATE \textbf{Skull stripping} using BET. Brain Extraction Tool deletes non-brain tissue from an image of the whole head. It can also estimate the inner and outer skull surfaces, and outer scalp surface, if you have good quality T1 and T2 input images.
		\STATE \textbf{Spatial Smoothing} via Full-Width at half maximum (FWHM) with 5mm range which is carried out on each volume of the FMRI data set separately. This is intended to reduce noise without reducing valid activation; this is successful as long as the underlying activation area is larger than the extent of the smoothing.
		\STATE \textbf{Highpass temporal filtering} uses a local fit of a straight line (Gaussian-weighted within the line to give a smooth response) to remove low frequency artifacts. Low level noises were removed using this filter with $t = 90 sec$.
		\STATE The functional images were then aligned to the individual's high-resolution T1-weighted scans, which were subsequently registered to the \textbf{Montreal Neurological Institute standard space (MNI152)} using affine linear registration and resampled at 2mm cubic voxels
	\end{algorithmic}
\end{algorithm}



Now we can start to train our model based on the proposed architecture which is illustrated in Figure \ref{fig:cnnArch}. During the training phase, data gets split to 50 chunks ($95$ samples) which are fed sequentially to the network. Consequently, the model can be validated during the training to prevent overfitting and enables us to track the whole process. The proposed method can be briefly expressed as Algorithm \ref{alg:proposedMethod} which $N_{i,p}$ indicates the number of predictions that instance $i$ is a Parkinson's patient and $N_{i,hc}$ indicates a Healthy Control. $\hat{Y}_{i,t}$ is the network prediction for $t$'th time-slice of sample $i$ whilst $Y_i$ is the real class and $C_{i,t}$ is the correctness of that output. Finally, $P_i$ is the predicted probability of how healthy a patient is, $\hat{Y}_i$ is the class based on $P_i$ and $C_i$ is the correctness of that prediction.



\begin{algorithm}
	\caption{Proposed method}
	\label{alg:proposedMethod}
	
	\begin{algorithmic}[1]
		
		\INPUT{processed data which is the output of Algorithm \ref{alg:preprocessing}.}
		\STATE Shuffle scans
		\STATE Put 6 scans (3 group each) aside as test data
		\STATE Split time-slices of data and shuffle them
		\STATE Divide train and validation data to 50 chunks
		\FORALL{50 chunks}  Train network (Fig. \ref{fig:cnnArch}) 
		\STATE Input dropout ($p=0.05$)
		\STATE 3D convolution ($4@64\times64\times39 \;;\; kernel[5,5,5]$)
		\STATE Dropout ($p=0.10$)
		\STATE Max pooling ($4@16\times16\times9 \;;\; pool[4,4,4]$)
		\STATE 3D convolution ($8@16\times16\times9 \;;\; kernel[4,4,4]$)
		\STATE Dropout ($p=0.15$)
		\STATE Max pooling ($8@4\times4\times2 \;;\; pool[4,4,4]$)
		\STATE Dropout ($p=0.20$)
		\STATE Fully connected layer ($16 \; units$)
		\STATE Dropout ($p=0.20$)
		\STATE Fully connected layer ($2 \; units$)
		\STATE Validate and emit network loss and accuracy
		\ENDFOR
		
		\FORALL{test data}
		\STATE $N_{i,p} \gets 0 \;,\; N_{i,hc} \gets 0 \;,\; C_{i,t} \gets 0$
		\FORALL{time-slices}
		\IF {$\hat{Y}_{i,t} =\; $Parkinson's} 
		\STATE $N_{i,p} \gets N_{i,p} + 1$
		\ELSE
		\STATE $N_{i,hc} \gets N_{i,hc} + 1$
		\ENDIF
		
		\IF {$\hat{Y}_{i,t} = Y_i$} 
		\STATE $C_{i,t} \gets 1$
		\ELSE 
		\STATE $C_{i,t} \gets 0$
		\ENDIF
		\ENDFOR
		
		\STATE ${P_{i}} \gets {N_{i,hc} \over T_{(=198)}}$
		
		\IF {$ P_{i} \geq 0.5$} \label{alg:proposedMethod:threshold}
		\STATE $\hat{Y}_i \gets \;$ Healthy Control
		\ELSE
		\STATE $\hat{Y}_i \gets \;$ Parkinson's
		\ENDIF
		
		\IF {$\hat{Y}_{i} = Y_{i}$} 
		\STATE $C_{i} \gets 1$
		\ELSE
		\STATE $C_{i} \gets 0$
		\ENDIF
		
		\ENDFOR
		
		%\IF {$i\geq 5$} 
		%\STATE $i\gets i-1$
		%\ELSE
		%\IF {$i\leq 3$}
		%\STATE $i\gets i+2$
		%\ENDIF
		%\ENDIF 
	\end{algorithmic}
	
	%	\KwData{pre-processed data which is the output of Algorithm \ref{alg:preprocessing}.}
	%	\KwResult{trained Bayesian 3D CNN to diagnose Parkinson's disease patients}
	%	initialization\;
	%	\While{not at end of this document}{
	%		read current\;
	%		\eIf{understand}{
	%			go to next section\;
	%			current section becomes this one\;
	%		}{
	%			go back to the beginning of current section\;
	%		}
	%	}
	
\end{algorithm}



Furthermore, our model's accuracy can be obtained in two different aspects. The first one would be the correctness of each time-slice prediction ($\overline{C}_{T}$), while the second, is the accuracy of disease diagnosis ($\overline{C}$), and we are mostly interested in the later. Both of the mentioned statistics can be calculated using Equations \eqref{eq:meanTimeSliceCorrectness} and \eqref{eq:meanCorrectness}.


\begin{figure*}
	\includegraphics[width=\linewidth]{images/cnnArchHorizontal}
	\caption{Proposed architecture}
	\label{fig:cnnHorizontalArch}
\end{figure*}

\begin{eqnarray}
\label{eq:meanTimeSliceCorrectness}
\overline{C_{T}} &=& {{\sum_{i=1}^{m} \sum_{t=1}^{T (=198)} C_{i,t} } \over {m \times T} } \\ 
\label{eq:meanCorrectness}
\overline{C} &=& {{\sum_{i=1}^{m} C_i } \over {m } } 
\end{eqnarray}



As can be seen in Figure \ref{fig:cnnHorizontalArch}, we have added different dropout units between our convolution and pooling layers to avoid overfitting, decrease variance and make convergence to appropriate weights faster. In addition to that, dropout probabilities increase in each layer because layers with less free parameters have a greater chance to train well even if they are less frequently updated. In other words, a huge number of parameters cannot tune acceptably with a small amount of data while getting omitted a lot. On the other hand, as there are only 16 weights in the first fully connected layer, higher dropout probabilities can speed up the training process.






\section{Experiments and results}
\label{section:results}
As discussed in Section \ref{section:proposedMethod}, our method does not demand high processing power so we can use a CPU for our experiments. All of the tests had been run on an Intel\textsuperscript{\tiny\textregistered} 4710HQ CPU. Averagely, the training phase takes $1h \; 12m \; 4s$ and the test phase finishes in $6m \; 41s$. As described in Section \ref{section:data}, Parkinson's disease dataset consists of 30 samples of 198 time-slices containing \texttt{$39 \times 64 \times 64$} {\tiny $=(159,744)$} voxels. Also it worth mentioning that the application consumes 270 megabytes of RAM thanks to the TFRECORD file format. Implementation of the proposed method in Python using TensorFlow\textsuperscript{\tiny\textregistered} can we found on \href{https://github.com/amin-amini/BayseanFmriDiseaseDiagnosis}{this Github repository} \cite{SourceCode}.

Table \ref{table:averageAccuracies} shows a summary of 8 different tests. We can define the average of mean accuracies as Equations \eqref{eq:averageMeanTimeSliceCorrectness} and \eqref{eq:averageMeanCorrectness} in order to use them as a measure that shows how the model is performing in the case of accuracy. 

\begin{eqnarray}
\label{eq:averageMeanTimeSliceCorrectness}
\mathbf{C_t} &=& {{\sum_{j=1}^{J} \overline{C_{T}} } \over {J} } \\ 
\label{eq:averageMeanCorrectness}
\mathbf{C} &=& {{\sum_{j=1}^{J} \overline{C} } \over {J} } 
\end{eqnarray}


\begin{table}
	\caption{Average accuracies for different tests}
	\centering
	\begin{tabular}{| c | c | c| }
		\hline
		$j$ & $\overline{C_{i,t}}\;(\%)$ & $\overline{C_i}\;(\%)$ \\ 
		test no. & mean time-slice accuracy & mean accuracy \\ \hline
		1 & 100 & 100 \\
		2 & 97.90 & 100 \\
		3 & 74.83 & 83.33 \\
		4 & 96.30 & 100 \\
		5 & 97.14 & 100 \\
		6 & 100 & 100 \\
		7 & 98.65 & 100 \\
		8 & 85.35 & 100 \\ \hline
		Average & $\mathbf{C_t} = $ 93.77 & $\mathbf{C} = $ 97.92 \\
		\hline
	\end{tabular}
\label{table:averageAccuracies}
\end{table}

As we can see, the proposed method has shown huge success in the task of Parkinson's disease diagnosis in an affordable time. Also, the fascinating point about the experiments is the average mean time-slice accuracy, which is around $92.96\%$. Accordingly, it means the model is able to judge only by a single time-slice of the brain while the prediction is acceptably accurate. We mostly care about the average mean accuracy, which is the average accuracy of the disease diagnosis task and as long as the whole process can predict someone's health situation precisely, we can ignore the time-slice based results. So, we should mostly focus on average mean accuracy and use that to compare the proposed method to other models. Experiment results can be seen in Tables \ref{table:tests_1} to \ref{table:tests_8} and Figures \ref{fig:tests_1} to  \ref{fig:tests_8}.




\begin{table}
	\caption{Test results for experiment 1. HC (Positive) stands for Health Control while P (Negative) means Parkinson's disease.}
	\resizebox{\linewidth}{!}{%
		\begin{tabular}{ | c | c | c | c | c | c | c | c | }
			\hline
			patient & $Y_i$ & $N_{hc}$ & $N_p$ & $C_{i,t} (\%)$ & $P_i$ & $\hat{Y}_i$ & $C_i (\%)$ \\  \hline
			CTL04 & HC & 198 &  0  & 100 & 1 & HC & 100 \\
			CTL05 & HC & 198 &  0  & 100 & 1 & HC & 100 \\
			CTL02 & HC & 198 &  0  & 100 & 1 & HC & 100 \\
			ODP04 & P   &  0  & 198 & 100 & 0 &  P  & 100 \\
			ODP05 & P   &  0  & 198 & 100 & 0 &  P  & 100 \\
			ODP02 & P   &  0  & 198 & 100 & 0 &  P  & 100 \\ \hline
			\multicolumn{4}{|r|}{\tiny{Mean time-slice accuracy} $\overline{C_{i,t}}$} & 100 &
			\multicolumn{2}{|r|}{\tiny{Mean accuracy} $\overline{C_{i}}$} & 100 \\
			\hline \hline
			
			\multicolumn{2}{|r|}{True positive (TP)} & 
			\multicolumn{2}{c|}{ 3 } &
			\multicolumn{2}{|r|}{False positive (FP)} & 
			\multicolumn{2}{c|}{ 0 } \\ 
			\multicolumn{2}{|r|}{False negative (FN)} & 
			\multicolumn{2}{c|}{ 0 } &
			\multicolumn{2}{|r|}{True negative (TN)} & 
			\multicolumn{2}{c|}{ 3 }  \\
			\hline \hline
			
			\multicolumn{2}{|r|}{Time-slice TP} & 
			\multicolumn{2}{c|}{ 594 } &
			\multicolumn{2}{|r|}{Time-slice FP} & 
			\multicolumn{2}{c|}{ 0 } \\ 
			\multicolumn{2}{|r|}{Time-slice FN} & 
			\multicolumn{2}{c|}{ 0 } &
			\multicolumn{2}{|r|}{Time-slice TN} & 
			\multicolumn{2}{c|}{ 594 }  \\
			\hline \hline
			
			\multicolumn{2}{|r|}{Time-slice sensitivity} & 
			\multicolumn{2}{c|}{ 1 } &
			\multicolumn{2}{|r|}{Sensitivity} & 
			\multicolumn{2}{c|}{ 1 } \\ 
			
			\multicolumn{2}{|r|}{Time-slice specificity} & 
			\multicolumn{2}{c|}{ 1 } &
			\multicolumn{2}{|r|}{Specificity} & 
			\multicolumn{2}{c|}{ 1 } \\ 
			
			\multicolumn{2}{|r|}{Time-slice PPV} & 
			\multicolumn{2}{c|}{ 1 } &
			\multicolumn{2}{|r|}{PPV} & 
			\multicolumn{2}{c|}{ 1 } \\ 
			
			\multicolumn{2}{|r|}{Time-slice NPV} & 
			\multicolumn{2}{c|}{ 1 } &
			\multicolumn{2}{|r|}{NPV} & 
			\multicolumn{2}{c|}{ 1 } \\ \hline
		\end{tabular}
	}
	\label{table:tests_1}
\end{table}
\begin{figure}
	\includegraphics[width=\linewidth]{images/tests_1}
	\caption{Experiment 1. Accuracy and loss of network for training and validation data. Accuracy is based on validation data and loss diagram contains train data loss in blue and validation loss in orange.}
	\label{fig:tests_1}
\end{figure}




\begin{table}
	\caption{Test results for experiment 2.}
	\resizebox{\linewidth}{!}{%
		\begin{tabular}{ | c | c | c | c | c | c | c | c | }
			\hline
			patient & $Y_i$ & $N_{hc}$ & $N_p$ & $C_{i,t} (\%)$ & $P_i$ & $\hat{Y}_i$ & $C_i (\%)$ \\  \hline
			CTL08 & HC & 191 &  7  & 96.46 & 0.9646 & HC & 100 \\
			CTL12 & HC & 195 &  3  & 98.48 & 0.9848 & HC & 100 \\
			CTL01 & HC & 198 &  0  & 100 & 1 & HC & 100 \\
			ODP08 & P   &  1  & 197 & 99.49 & 0.0050 &  P  & 100 \\
			ODP12 & P   &  2  & 196 & 98.99 & 0.0101 &  P  & 100 \\
			ODP01 & P   &  12  & 186 & 93.94 & 0.0606 &  P  & 100 \\ \hline
			\multicolumn{4}{|r|}{$\overline{C_{i,t}}$} & 97.90 &
			\multicolumn{2}{|r|}{$\overline{C_{i}}$} & 100 \\
			\hline \hline
			
			\multicolumn{2}{|r|}{True positive (TP)} & 
			\multicolumn{2}{c|}{ 3 } &
			\multicolumn{2}{|r|}{False positive (FP)} & 
			\multicolumn{2}{c|}{ 0 } \\ 
			\multicolumn{2}{|r|}{False negative (FN)} & 
			\multicolumn{2}{c|}{ 0 } &
			\multicolumn{2}{|r|}{True negative (TN)} & 
			\multicolumn{2}{c|}{ 3 }  \\
			\hline \hline
			
			\multicolumn{2}{|r|}{Time-slice TP} & 
			\multicolumn{2}{c|}{ 584 } &
			\multicolumn{2}{|r|}{Time-slice FP} & 
			\multicolumn{2}{c|}{ 15 } \\ 
			\multicolumn{2}{|r|}{Time-slice FN} & 
			\multicolumn{2}{c|}{ 10 } &
			\multicolumn{2}{|r|}{Time-slice TN} & 
			\multicolumn{2}{c|}{ 579 }  \\
			\hline \hline
			
			\multicolumn{2}{|r|}{Time-slice sensitivity} & 
			\multicolumn{2}{c|}{ 0.983164983 } &
			\multicolumn{2}{|r|}{Sensitivity} & 
			\multicolumn{2}{c|}{ 1 } \\ 
			
			\multicolumn{2}{|r|}{Time-slice specificity} & 
			\multicolumn{2}{c|}{ 0.974747475 } &
			\multicolumn{2}{|r|}{Specificity} & 
			\multicolumn{2}{c|}{ 1 } \\ 
			
			\multicolumn{2}{|r|}{Time-slice PPV} & 
			\multicolumn{2}{c|}{ 0.974958264 } &
			\multicolumn{2}{|r|}{PPV} & 
			\multicolumn{2}{c|}{ 1 } \\ 
			
			\multicolumn{2}{|r|}{Time-slice NPV} & 
			\multicolumn{2}{c|}{ 0.983022071 } &
			\multicolumn{2}{|r|}{NPV} & 
			\multicolumn{2}{c|}{ 1 } \\ \hline
		\end{tabular}
	}
	\label{table:tests_2}
\end{table}
\begin{figure}
	\includegraphics[width=\linewidth]{images/tests_2}
	\caption{Experiment 2. Accuracy and loss of network for training and validation data.}
	\label{fig:tests_2}
\end{figure}




\begin{table}
\caption{Test results for experiment 3.}
\resizebox{\linewidth}{!}{%
	\begin{tabular}{ | c | c | c | c | c | c | c | c | }
		\hline
		patient & $Y_i$ & $N_{hc}$ & $N_p$ & $C_{i,t} (\%)$ & $P_i$ & $\hat{Y}_i$ & $C_i (\%)$ \\  \hline
		CTL03 & HC & 198 &  0   &   100   &     1      & HC & 100 \\
		CTL13 & HC & 198 &  0   &   100   &     1      & HC & 100 \\
		CTL14 & HC & 198 &  0   &   100   &     1      & HC & 100 \\
		ODP03 & P  &  53  & 145 & 73.23 & 0.2677 &  P  & 100 \\
		ODP13 & P  & 198 &   0   &     0    &      1      & HC  & 0 \\
		ODP14 & P  & 48  &  150 & 75.76  & 0.2424 &  P  & 100 \\ \hline
		\multicolumn{4}{|r|}{$\overline{C_{i,t}}$} & 74.83 &
		\multicolumn{2}{|r|}{$\overline{C_{i}}$} & 83.33 \\
		\hline \hline
		
		\multicolumn{2}{|r|}{True positive (TP)} & 
		\multicolumn{2}{c|}{ 3 } &
		\multicolumn{2}{|r|}{False positive (FP)} & 
		\multicolumn{2}{c|}{ 1 } \\ 
		\multicolumn{2}{|r|}{False negative (FN)} & 
		\multicolumn{2}{c|}{ 0 } &
		\multicolumn{2}{|r|}{True negative (TN)} & 
		\multicolumn{2}{c|}{ 2 }  \\
		\hline \hline
		
		\multicolumn{2}{|r|}{Time-slice TP} & 
		\multicolumn{2}{c|}{ 594 } &
		\multicolumn{2}{|r|}{Time-slice FP} & 
		\multicolumn{2}{c|}{ 299 } \\ 
		\multicolumn{2}{|r|}{Time-slice FN} & 
		\multicolumn{2}{c|}{ 0 } &
		\multicolumn{2}{|r|}{Time-slice TN} & 
		\multicolumn{2}{c|}{ 295 }  \\
		\hline \hline
		
		\multicolumn{2}{|r|}{Time-slice sensitivity} & 
		\multicolumn{2}{c|}{ 1 } &
		\multicolumn{2}{|r|}{Sensitivity} & 
		\multicolumn{2}{c|}{ 1 } \\ 
		
		\multicolumn{2}{|r|}{Time-slice specificity} & 
		\multicolumn{2}{c|}{ 0.496632997 } &
		\multicolumn{2}{|r|}{Specificity} & 
		\multicolumn{2}{c|}{ 0.666666667 } \\ 
		
		\multicolumn{2}{|r|}{Time-slice PPV} & 
		\multicolumn{2}{c|}{ 0.665173572 } &
		\multicolumn{2}{|r|}{PPV} & 
		\multicolumn{2}{c|}{ 0.75 } \\ 
		
		\multicolumn{2}{|r|}{Time-slice NPV} & 
		\multicolumn{2}{c|}{ 1 } &
		\multicolumn{2}{|r|}{NPV} & 
		\multicolumn{2}{c|}{ 1 } \\ \hline
	\end{tabular}
}
\label{table:tests_3}
\end{table}
\begin{figure}
\includegraphics[width=\linewidth]{images/tests_3}
\caption{Experiment 3. Accuracy and loss of network for training and validation data.}
\label{fig:tests_3}
\end{figure}




\begin{table}
\caption{Test results for experiment 4.}
\resizebox{\linewidth}{!}{%
	\begin{tabular}{ | c | c | c | c | c | c | c | c | }
		\hline
		patient & $Y_i$ & $N_{hc}$ & $N_p$ & $C_{i,t} (\%)$ & $P_i$ & $\hat{Y}_i$ & $C_i (\%)$ \\  \hline
		CTL12 & HC & 185 & 13  & 93.43 & 0.9343 & HC & 100 \\
		CTL06 & HC & 197 &  1   & 99.49 & 0.9949 & HC & 100 \\
		CTL11 & HC & 170 & 28  & 85.86 & 0.8586 & HC & 100 \\
		ODP12 & P  &   0   & 198 &  100   &      0     &  P  & 100 \\
		ODP06 & P  &   0   & 198 &  100   &      0     &  P  & 100 \\
		ODP11 & P  &   2   & 196 & 98.99 & 0.0101  &  P  & 100 \\ \hline
		\multicolumn{4}{|r|}{$\overline{C_{i,t}}$} & 96.30 &
		\multicolumn{2}{|r|}{$\overline{C_{i}}$} & 100  \\
		\hline \hline
		
		\multicolumn{2}{|r|}{True positive (TP)} & 
		\multicolumn{2}{c|}{ 3 } &
		\multicolumn{2}{|r|}{False positive (FP)} & 
		\multicolumn{2}{c|}{ 0 } \\ 
		\multicolumn{2}{|r|}{False negative (FN)} & 
		\multicolumn{2}{c|}{ 0 } &
		\multicolumn{2}{|r|}{True negative (TN)} & 
		\multicolumn{2}{c|}{ 3 }  \\
		\hline \hline
		
		\multicolumn{2}{|r|}{Time-slice TP} & 
		\multicolumn{2}{c|}{ 552 } &
		\multicolumn{2}{|r|}{Time-slice FP} & 
		\multicolumn{2}{c|}{ 2 } \\ 
		\multicolumn{2}{|r|}{Time-slice FN} & 
		\multicolumn{2}{c|}{ 42 } &
		\multicolumn{2}{|r|}{Time-slice TN} & 
		\multicolumn{2}{c|}{ 592 }  \\
		\hline \hline
		
		\multicolumn{2}{|r|}{Time-slice sensitivity} & 
		\multicolumn{2}{c|}{ 0.929292929 } &
		\multicolumn{2}{|r|}{Sensitivity} & 
		\multicolumn{2}{c|}{ 1 } \\ 
		
		\multicolumn{2}{|r|}{Time-slice specificity} & 
		\multicolumn{2}{c|}{ 0.996632997 } &
		\multicolumn{2}{|r|}{Specificity} & 
		\multicolumn{2}{c|}{ 1 } \\ 
		
		\multicolumn{2}{|r|}{Time-slice PPV} & 
		\multicolumn{2}{c|}{ 0.996389892 } &
		\multicolumn{2}{|r|}{PPV} & 
		\multicolumn{2}{c|}{ 1 } \\ 
		
		\multicolumn{2}{|r|}{Time-slice NPV} & 
		\multicolumn{2}{c|}{ 0.933753943 } &
		\multicolumn{2}{|r|}{NPV} & 
		\multicolumn{2}{c|}{ 1 } \\ \hline
	\end{tabular}
}
\label{table:tests_4}
\end{table}
\begin{figure}
\includegraphics[width=\linewidth]{images/tests_4}
\caption{Experiment 4. Accuracy and loss of network for training and validation data.}
\label{fig:tests_4}
\end{figure}




\begin{table}
\caption{Test results for experiment 5.}
\resizebox{\linewidth}{!}{%
	\begin{tabular}{ | c | c | c | c | c | c | c | c | }
		\hline
		patient & $Y_i$ & $N_{hc}$ & $N_p$ & $C_{i,t} (\%)$ & $P_i$ & $\hat{Y}_i$ & $C_i (\%)$ \\  \hline
		CTL15 & HC & 198 &   0   &  100  & 1 & HC & 100 \\
		CTL11 & HC & 198  &   0   &  100  & 1 & HC & 100 \\
		CTL07 & HC & 198 &   0   &  100  & 1 & HC & 100 \\
		ODP15 & P   &   0   & 198 &  100  & 0 &  P  & 100 \\
		ODP11 & P   &  34  &  164 &82.83& 0.1717 &  P  & 100 \\
		ODP07 & P  &   0   &  198 & 1 00  &0  &  P  & 100 \\ \hline
		\multicolumn{4}{|r|}{$\overline{C_{i,t}}$} & 97.14 &
		\multicolumn{2}{|r|}{$\overline{C_{i}}$} & 100 \\
		\hline \hline
		
		\multicolumn{2}{|r|}{True positive (TP)} & 
		\multicolumn{2}{c|}{ 3 } &
		\multicolumn{2}{|r|}{False positive (FP)} & 
		\multicolumn{2}{c|}{ 0 } \\ 
		\multicolumn{2}{|r|}{False negative (FN)} & 
		\multicolumn{2}{c|}{ 0 } &
		\multicolumn{2}{|r|}{True negative (TN)} & 
		\multicolumn{2}{c|}{ 3 }  \\
		\hline \hline
		
		\multicolumn{2}{|r|}{Time-slice TP} & 
		\multicolumn{2}{c|}{ 594 } &
		\multicolumn{2}{|r|}{Time-slice FP} & 
		\multicolumn{2}{c|}{ 34 } \\ 
		\multicolumn{2}{|r|}{Time-slice FN} & 
		\multicolumn{2}{c|}{ 0 } &
		\multicolumn{2}{|r|}{Time-slice TN} & 
		\multicolumn{2}{c|}{ 560 }  \\
		\hline \hline
		
		\multicolumn{2}{|r|}{Time-slice sensitivity} & 
		\multicolumn{2}{c|}{ 1 } &
		\multicolumn{2}{|r|}{Sensitivity} & 
		\multicolumn{2}{c|}{ 1 } \\ 
		
		\multicolumn{2}{|r|}{Time-slice specificity} & 
		\multicolumn{2}{c|}{ 0.942760943 } &
		\multicolumn{2}{|r|}{Specificity} & 
		\multicolumn{2}{c|}{ 1 } \\ 
		
		\multicolumn{2}{|r|}{Time-slice PPV} & 
		\multicolumn{2}{c|}{ 0.945859873 } &
		\multicolumn{2}{|r|}{PPV} & 
		\multicolumn{2}{c|}{ 1 } \\ 
		
		\multicolumn{2}{|r|}{Time-slice NPV} & 
		\multicolumn{2}{c|}{ 1 } &
		\multicolumn{2}{|r|}{NPV} & 
		\multicolumn{2}{c|}{ 1 } \\ \hline
	\end{tabular}
}
\label{table:tests_5}
\end{table}
\begin{figure}
\includegraphics[width=\linewidth]{images/tests_5}
\caption{Experiment 5. Accuracy and loss of network for training and validation data.}
\label{fig:tests_5}
\end{figure}




\begin{table}
\caption{Test results for experiment 6.}
\resizebox{\linewidth}{!}{%
	\begin{tabular}{ | c | c | c | c | c | c | c | c | }
		\hline
		patient & $Y_i$ & $N_{hc}$ & $N_p$ & $C_{i,t} (\%)$ & $P_i$ & $\hat{Y}_i$ & $C_i (\%)$ \\  \hline
		CTL10 & HC & 198 &  0 & 100 & 1 & HC & 100 \\
		CTL03 & HC & 198 &  0 & 100 & 1 & HC & 100 \\
		CTL02 & HC & 198 &  0 & 100 & 1 & HC & 100 \\
		ODP10 & P  &  0  & 198 & 100 & 0 &  P  & 100 \\
		ODP03 & P  &  0  & 198 & 100 & 0 &  P  & 100 \\
		ODP02 & P  &  0  & 198 & 100 & 0 &  P  & 100 \\ \hline
		\multicolumn{4}{|r|}{$\overline{C_{i,t}}$} & 100 &
		\multicolumn{2}{|r|}{$\overline{C_{i}}$} & 100 \\
		\hline \hline
		
		\multicolumn{2}{|r|}{True positive (TP)} & 
		\multicolumn{2}{c|}{ 3 } &
		\multicolumn{2}{|r|}{False positive (FP)} & 
		\multicolumn{2}{c|}{ 0 } \\ 
		\multicolumn{2}{|r|}{False negative (FN)} & 
		\multicolumn{2}{c|}{ 0 } &
		\multicolumn{2}{|r|}{True negative (TN)} & 
		\multicolumn{2}{c|}{ 3 }  \\
		\hline \hline
		
		\multicolumn{2}{|r|}{Time-slice TP} & 
		\multicolumn{2}{c|}{ 594 } &
		\multicolumn{2}{|r|}{Time-slice FP} & 
		\multicolumn{2}{c|}{ 0 } \\ 
		\multicolumn{2}{|r|}{Time-slice FN} & 
		\multicolumn{2}{c|}{ 0 } &
		\multicolumn{2}{|r|}{Time-slice TN} & 
		\multicolumn{2}{c|}{ 594 }  \\
		\hline \hline
		
		\multicolumn{2}{|r|}{Time-slice sensitivity} & 
		\multicolumn{2}{c|}{ 1 } &
		\multicolumn{2}{|r|}{Sensitivity} & 
		\multicolumn{2}{c|}{ 1 } \\ 
		
		\multicolumn{2}{|r|}{Time-slice specificity} & 
		\multicolumn{2}{c|}{ 1 } &
		\multicolumn{2}{|r|}{Specificity} & 
		\multicolumn{2}{c|}{ 1 } \\ 
		
		\multicolumn{2}{|r|}{Time-slice PPV} & 
		\multicolumn{2}{c|}{ 1 } &
		\multicolumn{2}{|r|}{PPV} & 
		\multicolumn{2}{c|}{ 1 } \\ 
		
		\multicolumn{2}{|r|}{Time-slice NPV} & 
		\multicolumn{2}{c|}{ 1 } &
		\multicolumn{2}{|r|}{NPV} & 
		\multicolumn{2}{c|}{ 1 } \\ \hline
	\end{tabular}
}
\label{table:tests_6}
\end{table}
\begin{figure}
\includegraphics[width=\linewidth]{images/tests_6}
\caption{Experiment 6. Accuracy and loss of network for training and validation data.}
\label{fig:tests_6}
\end{figure}




\begin{table}
\caption{Test results for experiment 7.}
\resizebox{\linewidth}{!}{%
	\begin{tabular}{ | c | c | c | c | c | c | c | c | }
		\hline
		patient & $Y_i$ & $N_{hc}$ & $N_p$ & $C_{i,t} (\%)$ & $P_i$ & $\hat{Y}_i$ & $C_i (\%)$ \\  \hline
		CTL05 & HC & 194 &  4   & 97.98 & 0.9798 & HC & 100 \\
		CTL04 & HC & 198 &  0   &   100  &      1     & HC & 100 \\
		CTL10 & HC & 186  &  12 & 93.94 & 0.9394 & HC & 100 \\
		ODP05 & P  &   0   & 198 &   100  &     0     &  P  & 100 \\
		ODP04 & P  &   0   & 198 &   100  &     0     &  P  & 100 \\
		ODP10 & P  &   0    & 198 &   100  &    0      &  P  & 100 \\ \hline
		\multicolumn{4}{|r|}{$\overline{C_{i,t}}$} & 98.65 &
		\multicolumn{2}{|r|}{$\overline{C_{i}}$} & 100 \\
		\hline \hline
		
		\multicolumn{2}{|r|}{True positive (TP)} & 
		\multicolumn{2}{c|}{ 3 } &
		\multicolumn{2}{|r|}{False positive (FP)} & 
		\multicolumn{2}{c|}{ 0 } \\ 
		\multicolumn{2}{|r|}{False negative (FN)} & 
		\multicolumn{2}{c|}{ 0 } &
		\multicolumn{2}{|r|}{True negative (TN)} & 
		\multicolumn{2}{c|}{ 3 }  \\
		\hline \hline
		
		\multicolumn{2}{|r|}{Time-slice TP} & 
		\multicolumn{2}{c|}{ 578 } &
		\multicolumn{2}{|r|}{Time-slice FP} & 
		\multicolumn{2}{c|}{ 0 } \\ 
		\multicolumn{2}{|r|}{Time-slice FN} & 
		\multicolumn{2}{c|}{ 16 } &
		\multicolumn{2}{|r|}{Time-slice TN} & 
		\multicolumn{2}{c|}{ 594 }  \\
		\hline \hline
		
		\multicolumn{2}{|r|}{Time-slice sensitivity} & 
		\multicolumn{2}{c|}{ 0.973063973 } &
		\multicolumn{2}{|r|}{Sensitivity} & 
		\multicolumn{2}{c|}{ 1 } \\ 
		
		\multicolumn{2}{|r|}{Time-slice specificity} & 
		\multicolumn{2}{c|}{ 1 } &
		\multicolumn{2}{|r|}{Specificity} & 
		\multicolumn{2}{c|}{ 1 } \\ 
		
		\multicolumn{2}{|r|}{Time-slice PPV} & 
		\multicolumn{2}{c|}{ 1 } &
		\multicolumn{2}{|r|}{PPV} & 
		\multicolumn{2}{c|}{ 1 } \\ 
		
		\multicolumn{2}{|r|}{Time-slice NPV} & 
		\multicolumn{2}{c|}{ 0.973770492 } &
		\multicolumn{2}{|r|}{NPV} & 
		\multicolumn{2}{c|}{ 1 } \\ \hline
	\end{tabular}
}
\label{table:tests_7}
\end{table}
\begin{figure}
\includegraphics[width=\linewidth]{images/tests_7}
\caption{Experiment 7. Accuracy and loss of network for training and validation data.}
\label{fig:tests_7}
\end{figure}




\begin{table}
\caption{Test results for experiment 8.}
\resizebox{\linewidth}{!}{%
	\begin{tabular}{ | c | c | c | c | c | c | c | c | }
		\hline
		patient & $Y_i$ & $N_{hc}$ & $N_p$ & $C_{i,t} (\%)$ & $P_i$ & $\hat{Y}_i$ & $C_i (\%)$ \\  \hline
		CTL09 & HC & 102 & 96  & 51.51 &  0.5151 & HC  & 100 \\
		CTL12 & HC & 122 &  76  & 61.62 & 0.6162 & HC & 100 \\
		CTL06 & HC & 198 &   0  &  100   &    1       & HC & 100 \\
		ODP09 & P  &   0   & 198 &  100   &    0       &  P  & 100 \\
		ODP12 &  P  &   2   & 196 & 98.99 & 0.0101 &  P  & 100 \\
		ODP06 & P  &   0   & 198 &  100   &    0       &  P  & 100 \\ \hline
		\multicolumn{4}{|r|}{$\overline{C_{i,t}}$} & 85.35 &
		\multicolumn{2}{|r|}{$\overline{C_{i}}$} & 100 \\
		\hline \hline
		
		\multicolumn{2}{|r|}{True positive (TP)} & 
		\multicolumn{2}{c|}{ 3 } &
		\multicolumn{2}{|r|}{False positive (FP)} & 
		\multicolumn{2}{c|}{ 0 } \\ 
		\multicolumn{2}{|r|}{False negative (FN)} & 
		\multicolumn{2}{c|}{ 0 } &
		\multicolumn{2}{|r|}{True negative (TN)} & 
		\multicolumn{2}{c|}{ 3 }  \\
		\hline \hline
		
		\multicolumn{2}{|r|}{Time-slice TP} & 
		\multicolumn{2}{c|}{ 422 } &
		\multicolumn{2}{|r|}{Time-slice FP} & 
		\multicolumn{2}{c|}{ 2 } \\ 
		\multicolumn{2}{|r|}{Time-slice FN} & 
		\multicolumn{2}{c|}{ 172 } &
		\multicolumn{2}{|r|}{Time-slice TN} & 
		\multicolumn{2}{c|}{ 592 }  \\
		\hline \hline
		
		\multicolumn{2}{|r|}{Time-slice sensitivity} & 
		\multicolumn{2}{c|}{ 0.71043771 } &
		\multicolumn{2}{|r|}{Sensitivity} & 
		\multicolumn{2}{c|}{ 1 } \\ 
		
		\multicolumn{2}{|r|}{Time-slice specificity} & 
		\multicolumn{2}{c|}{ 0.996632997 } &
		\multicolumn{2}{|r|}{Specificity} & 
		\multicolumn{2}{c|}{ 1 } \\ 
		
		\multicolumn{2}{|r|}{Time-slice PPV} & 
		\multicolumn{2}{c|}{ 0.995283019 } &
		\multicolumn{2}{|r|}{PPV} & 
		\multicolumn{2}{c|}{ 1 } \\ 
		
		\multicolumn{2}{|r|}{Time-slice NPV} & 
		\multicolumn{2}{c|}{ 0.77486911 } &
		\multicolumn{2}{|r|}{NPV} & 
		\multicolumn{2}{c|}{ 1 } \\ \hline
	\end{tabular}
}
\label{table:tests_8}
\end{table}
\begin{figure}
\includegraphics[width=\linewidth]{images/tests_8}
\caption{Experiment 8. Accuracy and loss of network for training and validation data.}
\label{fig:tests_8}
\end{figure}



Also we tested two other methods for comparison, First Sarraf and Tofighi's method \cite{Sarraf2016} which had been described in the beginning of Section \ref{section:proposedMethod} which required a powerful GPU for calculations, had a lot of small assumptions about the data but faced overfitting in all 4 different experiments (Accuracies: [$66.67\%$ , $50\%$ , $50\%$ , $16.67\%$]). Second method is a SVM based method proposed by Rashid et al \cite{Rashid2016} for classification of schizophrenia and bipolar patients based on functional network connectivities. This method takes some assumptions about the data and is not easily expandable to other diseases but I tried it as a competitor (Accuracies: [$83.33\%$ , $66.67\%$ , $66.67\%$ , $16.67\%$]). The comparison can be seen in Table \ref{table:comparison}.



\begin{table}
	\caption{Comparison of the proposed method with 2 other rivals}
	\resizebox{\linewidth}{!}{%
	\begin{tabular}{| c | c | c | c | }
		\hline
		Method & \shortstack{Average \\ accuracy (\%)} & \shortstack{Average \\ time (min)} & \shortstack{Test \\ hardware} \\ \hline
		
		Proposed Method & 97.92 & 72.06 & CPU {\tiny{(Intel4710HQ)}} \\
		Sarraf and Tofighi & 45.83 & 407.6 & GPU {\tiny{(GTX1080)}} \\
		Rashid et al.          & 58.33 & 23.13 & CPU {\tiny{(Intel4710HQ)}} \\ \hline
	\end{tabular}
}
	\label{table:comparison}
\end{table}






\section{Discussion}
\label{section:discussion}

Our results suggest that the classification of Parkinson’s disease patients using fMRI data can be done accurately without taking time-based information in calculations. Also, this is supported by statistics such as Accuracy, Sensitivity, Specificity, Positive and Negative Predictive Values. Moreover, it is obvious that predictions using only one time-slice can be very powerful and enables us to obtain a probability of how healthy a patient is. On the other hand, this method does not require to omit any time-slices from scans to unify them, unlike other methods that use this approach to find functional network connectivities. Additionally, the proposed method does not make any assumptions based on any information, and it might be able to be used to classify other diseases as well.

Test results show the method did not face overfitting thanks to the dropout layers. As discussed in Section \ref{section:bayesianDL}, our network is a Bayesian 3D CNN that can learn from a small amount of data without memorizing them, just like other Bayesian networks. Experiment 3 is the only test that our model failed to predict the health status of samples precisely and did 1 mistake. However, our model did not overfit hugely, it just could not solve the problem acceptably, and if we take a look at Figure \ref{fig:tests_3}, it is obvious that the validation accuracy is less than $80\%$. As a result, the proposed method can train with low calculation costs and the trained model is reliable based on experiments.

The proposed method has shown better results in Parkinson's disease diagnosis task compared to two other methods which can be seen in Table \ref{table:comparison}. However, Rashid et al. SVM based method is approximately 3 times faster and in case of time efficiency and speed, it seems far better. On the other hand, Sarraf and Tofighi's method demands a powerful processing unit alongside a huge amount of time. Finally, the proposed method is the most accurate undoubtedly and can solve the problem in a reasonable time.

We can change, tune and improve a lot of factors from Algorithm \ref{alg:proposedMethod}. First of all, the threshold of healthiness at line~\ref{alg:proposedMethod:threshold} can change to any other number instead of $0.5$, which may require advice from a consultant or a doctor. Also, dropout probabilities are important and somehow hard to find any rule for them. We did some experiments and mentioned probabilities were good enough to solve the problem. In addition to that, it is possible to change network architecture by manipulating parameters such as the number of filters and the size of kernels in pooling and convolution layers.

As we can see, the overall shape of the diagrams (loss and accuracy) in Figures \ref{fig:tests_1} to \ref{fig:tests_8} are extremely different than normal CNNs, as can bee seen in Figure \ref{fig:SarrafParkinsonTestResult}. This behavior is the result of using dropouts which prevent gradient descent to smoothly decrease loss \cite{Gal2016}. These smooth steps can be seen in small parts of the diagram but not in the whole diagram. As we add dropout layers, gradient descent tries to minimize the loss of the training. As long as the dropout layers stay the same, everything works as expected. However, as the dropout layers vary, the loss changes dramatically and as a result, the loss diagram becomes noisy.

In conclusion, fMRI data contains a lot of both temporal and spatial information and we can take advantage of them if we find proper models. Our proposed method can classify patients based on spatial information only and does not use any kind of time based models or temporal data. Also, our research verifies that each fMRI time-slice contains enough information to diagnose diseases and is acceptably accurate.











\section{Limitations and future directions}
\label{section:future}
It is really difficult to make comparisons among different automatic classification approaches of diseases, as there are several limitations and considerations associated with these studies. Factors such as fMRI scanner parameters, study size, type of classifier, nature of extracted features, medication and disease severity in the patient groups affect the classification framework. Also, without standard training and testing datasets, a comparison of different approaches based only on the classification accuracy becomes vague and highly ambiguous.

If we want to use this model to diagnose different diseases, we need to train several networks because a patient can suffer from two diseases at the same time and the proposed method will give a probability of how healthy a patient is, which is bounded in the context of a specific disease. Subsequently, if our networks have been trained with various input data, the chance of having models with different input sizes is so high. Thus, we need to find a proper way to standardize inputs before using them.

Our approach has some bias as the whole dataset was obtained from one center and was pre-processed together in the beginning. To resolve this issue, we can try to examine the proposed method on a bigger dataset consisted of different scans obtained using different instruments. Also, we can include other diseases (such as Alzheimer and Schizophrenia) patients as healthy control, to see how the proposed method will do the job.

To improve this method, we can try to investigate more on data and results to tune dropout probabilities and detection threshold (line~\ref{alg:proposedMethod:threshold} of Algorithm \ref{alg:proposedMethod}). In addition to that, we can try to employ competitor neural networks such as GoogleNet and try to utilize them using Bayesian methods in the task of Parkinson's disease diagnosis. Furthermore, we will be able to compare the proposed method to other rivals and improve this model.

In this study, we showed that spatial information is powerful enough to diagnose Parkinson's disease. Moreover, we can try to implement a hybrid solution based on the proposed method that uses temporal connectivities as well. For instance, we can use functional connectivity based algorithms \cite{Rashid2016} \cite{Shen2014} \cite{Calhoun2004} \cite{GonzalezCastillo2015} \cite{Greicius2002} \cite{Arribas2010} \cite{Leonardi2013} \cite{Liu2015} \cite{Liu2016} \cite{Lehmann2017} \cite{Ryali2012} or statistical/Bayesian based methods \cite{HanchuanPeng2005} \cite{Flandin2007} \cite{Ahmad2016} \cite{Power2012} \cite{Oikonomou2010} \cite{GomezLaberge2011} \cite{Zhang2001} \cite{Oikonomou2012} \cite{Oikonomou2013} \cite{Younes2006} \cite{Suk2016} \cite{Calhoun2012}. Ensembling can be done by training mentioned methods combined with Bayesian units or by adding their extracted features to the existing network.











\begin{figure}
	\centering
	\includegraphics[scale=.6]{images/cnnArch}
	\caption{Proposed Bayesian 3D CNN architecture}
	\label{fig:cnnArch}
\end{figure}

\appendix

%\section{My Appendix}
%Appendix sections are coded under \verb+\appendix+.

%\verb+\printcredits+ command is used after appendix sections to list 
%author credit taxonomy contribution roles tagged using \verb+\credit+ 
%in frontmatter.

%\printcredits

%% Loading bibliography style file
%\bibliographystyle{model1-num-names}
\bibliographystyle{cas-model2-names}

% Loading bibliography database
\bibliography{refs}


%\vskip3pt


\end{document}

